# Chapter 1. General Probability Theory

## 1.1 Infinite Probability Spaces

**Infinite Probability Space**: A situation in which a random experiment with infinitely many possible outcomes is conducted. 
**Two Experiments**   
- (i) choose a number from the unit interval [0,1]
- (ii) toss a coin infinitely many times

For  (i), sample space: $\omega$ = the unite interval [0, 1].  
For (ii), sample space: $\Omega_\inf$ = the set of infinite sequences of $H_s$ and $T_s$.

----------------------------------------------------------------
### Definition 1.1.1 
Let $\Omega$ be a nonempty set, and let $F$ be a collection of subsets of $\Omega$. We say that $F$ is a $\sigma$-algebra (or $\sigma$-field) provided that:

(i) the empty set $0$ belongs to $F$  
(ii) whenever a set $A$ belgons to $F$, its  complement $A^c$ also belongs to $F$, and    
(iii) wheenver a sequence of sets $A_1$, $A_2$, ... belongs to $F$, their union $\cup_{n=1}^{\inf} A_n$ also belongs to $F$.

----------------------------------------------------------------

----------------------------------------------------------------
### Definition 1.1.2 
Let $\Omega$ be a nonempty set, and let $F$ be a collection of subsets of $\Omega$. A probability measure $\mathbb{P}$ is a function that, to every set $A \subset F$, assigns a number in [0, 1], *called* the probability of $A$ and written $\mathbb{P}(A)$. We requre:

(i) $\mathbb{P}(\Omega)$ = 1 and   
(ii) (countable additivity) whenever $A_1$, $A_2$,... is a sequence of disjoint sets in $F$, then  
$$\mathbb{P}(\cup_{n=1}^{\inf} A_n) = \Sigma_{n=1}^{\inf} \mathbb{P}(A_n).$$  
*The triple* ($\Omega$, $F$, $\mathbb{P}$) *is called* a probability space.

----------------------------------------------------------------
 
 #### Example (i): Choose number from [0, 1]
 
 Let probability of closed intervals [a, b] define as $\mathbb{P}[a,b] = b-a$, $0 \le a \le b \le 1$.  
 With this definition, $\mathbb{P}[a, a] = \mathbb{P}[a] = a - a = 0$.   
 
 The $\sigma$-algebra obtained by beginning with closed intervals and adding everything else necessary called *Borel* $\sigma$-*algebra* of subset of [0, 1] and is denoted $B[0,1]$. 
 
 
 #### Example (ii): infinite coin toss
 
 Let probabilty of head on each toss is $p$ and probability of tail on each toss is $q = 1-p$.   
 We can construct the $\sigma$-algebra on this example.
 
 1) 0 Toss: $F_0 = {0, \Omega}$
 2) 1 Toss:
     $A_H$ = {all sequence beginning with $H$}   
     $A_T$ = {all sequence beginning with $T$}  
     
     Then, $F_1 = \{0, \Omega, A_H, A_T\}$ with $A_H = p$ and $A_T = q$.
     
 3) 2 Toss:
      $A_{HH}$ = {all sequence beginning with $HH$}
      $A_{HT}$ = {all sequence beginning with $HT$}
      $A_{TH}$ = {all sequence beginning with $TH$}
      $A_{TT}$ = {all sequence beginning with $TT$}
      
      To construct the $\sigma$-algebra, we need the probability of the complements and probabilities of the unions.  
      
      Then, $F_2 = {0, \Omega, A_H, A_T, A_{HH}, A_{TT}, A_{HT}, A_{TH}, A_{HH}^c, A_{TT}^c, A_{HT}^c, A_{TH}^c, A_{HH} \cup A_{TH}, A_{HH} \cup A_{TT}, A_{HT} \cup A_{TH}, A_{HT} \cup A_{TT}}$
      
## 1.2 Random Variables and Distributions

----------------------------------------------------------------
### Definition 1.2.1 
Let ($\Omega$, $F$, $\mathbb{P}$) be a *probability* space. A random variable *is a real-valued function* $X$ *defined on* $\Omega$ *with the property that for every Borel subset* $B$ of $\mathbb{R}$, *the subset of* $\Omega$ *given by*

$$\{X \subset B \} = \{ \omega \subset \Omega; X(\omega) \subset B \}$$

is in the $\sigma$-algebra $F$. 

----------------------------------------------------------------
      
----------------------------------------------------------------
### Definition 1.2.2 
Let X be a random variable on a probability space ($\Omega$, $F$, $\mathbb{P}$). The distribution measure of $X$ is the probaboility measure $\mu_X$ that assigns to each Borel subset of $B$ of $\mathbb{R}$ the mass $\mu_X(B) = \mathbb{P}(X \subset B)$.

----------------------------------------------------------------

## 1.3 Expectations

Let $X$ be a random variable defined on on a probability space ($\Omega$, $F$, $\mathbb{P}$). If $\Omega$ is finite,

$$\mathbb{E}X = \Sigma_{\omega \subset \Omega} X(\omega) \mathbb{P}(\omega)$$

If $\Omega$ is countably infinite,

$$\mathbb{E}X = \Sigma_{\omega \subset \Omega}^{\inf} X(\omega_k) \mathbb{P}(\omega_k)$$

However, if $\Omega$ is uncountably infinite, uncountable sums cannot be defined. Instead, we must think in terms of integrals.

